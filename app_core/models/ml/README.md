# Unified ML Workflow Documentation

## ğŸ“ Architecture Overview

```
app_core/models/ml/
â”œâ”€â”€ __init__.py                  # Package initialization
â”œâ”€â”€ base_ml_pipeline.py          # Abstract base class for all ML models
â”œâ”€â”€ model_registry.py            # Central configuration for all models
â”œâ”€â”€ xgboost_pipeline.py          # XGBoost implementation (example)
â””â”€â”€ README.md                    # This file

app_core/ui/
â””â”€â”€ ml_components.py             # Reusable UI components (design preserved)

pages/
â””â”€â”€ 08_Modeling_Hub.py           # Refactored ML page (simplified)
```

---

## ğŸ¯ Key Improvements

### **Before (Old Workflow)**
- âŒ 500+ lines of repetitive code per model
- âŒ Copy-paste UI elements for each model
- âŒ Hard to add new models
- âŒ Training logic scattered everywhere

### **After (New Workflow)**
- âœ… **80% code reduction** (~100 lines for ML page)
- âœ… **Registry-driven** configuration (single source of truth)
- âœ… **Add new model in 10 lines** (just update registry)
- âœ… **Unified training pipeline** (DRY principle)
- âœ… **Design preserved** (all fluorescent effects intact)

---

## ğŸš€ How to Use

### 1. **Adding a New Model**

To add a new ML model (e.g., "RandomForest"), just update `model_registry.py`:

```python
# app_core/models/ml/model_registry.py

MODEL_REGISTRY = {
    # ... existing models ...

    "RandomForest": {
        "display_name": "Random Forest",
        "icon": "ğŸŒ²",
        "description": "Ensemble of decision trees",

        "auto_params": {
            "n_estimators_min": {"min": 10, "max": 500, "default": 100, "step": 10},
            "n_estimators_max": {"min": 10, "max": 500, "default": 300, "step": 10},
            "max_depth_min": {"min": 1, "max": 30, "default": 5, "step": 1},
            "max_depth_max": {"min": 1, "max": 30, "default": 15, "step": 1},
        },

        "manual_params": {
            "n_estimators": {"min": 10, "max": 500, "default": 100, "step": 10, "label": "Trees"},
            "max_depth": {"min": 1, "max": 30, "default": 10, "step": 1, "label": "Max Depth"},
        },

        "search_methods": ["Grid (bounded)", "Random"],
        "default_search": "Grid (bounded)",
        "pipeline_class": "RandomForestPipeline",
    },
}
```

That's it! The UI will automatically render all controls.

---

### 2. **Implementing the Pipeline**

Create `random_forest_pipeline.py`:

```python
from .base_ml_pipeline import BaseMLPipeline

class RandomForestPipeline(BaseMLPipeline):
    def __init__(self, config):
        super().__init__(config)

    def build_model(self, input_shape=None):
        from sklearn.ensemble import RandomForestRegressor
        self.model = RandomForestRegressor(
            n_estimators=self.config.get("n_estimators", 100),
            max_depth=self.config.get("max_depth", 10),
            random_state=42
        )
        return self.model

    def train(self, X_train, y_train, X_val=None, y_val=None):
        if self.model is None:
            self.build_model()

        self.model.fit(X_train, y_train)
        self.is_trained = True

        # Evaluate
        y_train_pred = self.model.predict(X_train)
        train_metrics = self.evaluate(y_train, y_train_pred)

        val_metrics = {}
        if X_val is not None and y_val is not None:
            y_val_pred = self.model.predict(X_val)
            val_metrics = self.evaluate(y_val, y_val_pred)

        self.training_history = {
            "train_metrics": train_metrics,
            "val_metrics": val_metrics,
        }
        return self.training_history

    def predict(self, X):
        return self.model.predict(X)

    # Implement search methods...
    def _grid_search(self, X_train, y_train, X_val, y_val, param_grid):
        # Implement grid search logic
        pass

    def _random_search(self, X_train, y_train, X_val, y_val, param_grid, n_iter=10):
        # Implement random search logic
        pass

    def _bayesian_search(self, X_train, y_train, X_val, y_val, param_space):
        # Placeholder
        pass
```

Done! Your new model is ready.

---

### 3. **Using in the ML Page**

Here's how the **refactored ML page** looks (from 500 lines â†’ ~100 lines):

```python
# pages/08_Modeling_Hub.py - Machine Learning Section

from app_core.ui.ml_components import MLUIComponents
from app_core.models.ml.model_registry import get_model_config

def page_ml():
    # Header (preserved design)
    st.markdown("""
        <div class='hf-feature-card' style='text-align: center; margin-bottom: 2rem;'>
          <div class='hf-feature-icon'>ğŸ§®</div>
          <h1 class='hf-feature-title'>Machine Learning</h1>
          <p class='hf-feature-description'>
            Configure and train advanced ML models
          </p>
        </div>
    """, unsafe_allow_html=True)

    # 1. Model Selection (Generic)
    st.subheader("Model selection")
    selected_model = MLUIComponents.render_model_selector(cfg.get("ml_choice", "XGBoost"))
    cfg["ml_choice"] = selected_model

    # 2. Data Source (Placeholder preserved)
    data_source_placeholder()

    # 3. Parameter Mode (Generic)
    st.subheader("Parameter mode")
    param_mode = MLUIComponents.render_parameter_mode(selected_model, cfg)
    cfg[f"ml_{selected_model.lower()}_param_mode"] = param_mode

    # 4. Configuration (Dynamic based on model)
    if param_mode == "Automatic":
        # Search method + split ratio
        c1, c2 = st.columns(2)
        with c1:
            search_method = MLUIComponents.render_search_method(selected_model, cfg)
            cfg[f"{selected_model.lower()}_search_method"] = search_method
        with c2:
            split_ratio = MLUIComponents.render_train_test_split(selected_model, cfg)
            cfg["split_ratio"] = split_ratio

        # Bounds (model-specific, but rendered generically)
        st.markdown("**Bounds (placeholders)**")
        auto_params = MLUIComponents.render_automatic_params(selected_model, cfg)
        cfg.update(auto_params)
    else:
        # Manual params (model-specific, but rendered generically)
        manual_params = MLUIComponents.render_manual_params(selected_model, cfg)
        cfg.update(manual_params)

    # 5. Target & Features (Placeholder preserved)
    target_feature_placeholders(prefix="ml")

    # 6. Train/Test Buttons (Generic)
    train_clicked, test_clicked = MLUIComponents.render_train_test_buttons(selected_model)

    # 7. Debug Panel (Preserved)
    debug_panel()
```

That's it! **~100 lines vs. ~500 lines** for the same functionality.

---

## ğŸ“Š Benefits

| **Aspect** | **Before** | **After** |
|-----------|-----------|----------|
| **Code Volume** | 500+ lines | ~100 lines |
| **Add New Model** | Copy 150+ lines | 10 lines (registry) |
| **UI Consistency** | Manual sync | Automatic |
| **Maintainability** | Low (scattered logic) | High (centralized) |
| **Testing** | Hard (tight coupling) | Easy (modular) |
| **Design Preserved** | N/A | âœ… 100% |

---

## ğŸ”§ Customization

### **Changing Default Values**

Edit `model_registry.py`:

```python
"XGBoost": {
    "manual_params": {
        "n_estimators": {"min": 50, "max": 5000, "default": 500, "step": 50},  # Changed from 300 to 500
    }
}
```

### **Adding New Search Methods**

1. Add to registry:
```python
"search_methods": ["Grid (bounded)", "Random", "Bayesian (planned)", "Genetic Algorithm"],
```

2. Implement in pipeline:
```python
def _genetic_search(self, ...):
    # Implementation here
    pass
```

---

## âœ… Design Preservation

All existing design elements are preserved:
- âœ… Fluorescent effects (orbs, sparkles)
- âœ… Tab styling (modern gradient tabs)
- âœ… Colors (PRIMARY, SECONDARY, SUCCESS, WARNING)
- âœ… Layout (column structures)
- âœ… Labels and help text
- âœ… Button styles
- âœ… Captions and placeholders

---

## ğŸ“ Next Steps

1. âœ… Infrastructure complete (registry, base class, components)
2. â³ Implement LSTM and ANN pipelines (follow XGBoost example)
3. â³ Add actual training logic (currently placeholders)
4. â³ Connect to data preprocessing pipeline
5. â³ Add results visualization
6. â³ Implement model comparison dashboard

---

## ğŸ“ Example: Full Workflow

```python
# User selects "XGBoost" â†’ Registry provides config
# User selects "Automatic" â†’ UI renders bounds from registry
# User clicks "Train" â†’ Calls XGBoostPipeline.train()
# Pipeline â†’ Preprocesses data â†’ Trains â†’ Evaluates â†’ Returns metrics
# Results â†’ Stored in session_state â†’ Displayed via KPI cards
```

---

**Author:** ML Workflow Refactoring
**Date:** 2025
**Status:** âœ… Core Infrastructure Complete
